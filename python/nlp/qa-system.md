# QA System

@see: https://mp.weixin.qq.com/s/eibDMYADPiOjlLBo74UTdQ

ELIZA Transformer 很简单:

1. 本地模式匹配
2. 两种长期记忆机制(循环遍历响应和记忆队列)

本地模式匹配就是模型有一套**关键词**和**规则**, 当它看到用户说的话里包含这些关键词时, 就能按照规则给出回应.

而且，ELIZA 会记住以前是怎么回答类似问题的，然后换着花样给出不同的回答(通过**记忆队列**)

核心就是 4 个子任务:

1. input segmentation
2. template matching
3. rule selection
4. answer generation

证明了:

1. Transformer 模型倾向于使用注意力机制来识别和复制序列中的特定模式, 而非严格按照词的位置来复制
2. 即使没有特别为记忆设计的工具, 模型也能通过自己的计算过程来实现记忆效果

## step1

第一步, 将输入分成多个段落

这里输入的是对话历史，包括用户的输入(标记为“u：”)和 ELIZA 的响应(标记为“e：”)

在多轮对话中，用户输入和 ELIZA 响应会形成一个连续的序列，然后 Transformer 模型使用自注意力机制来处理这些输入。它能够通过注意力权重来识别对话中的重要部分，并据此生成响应

## step2

使用的是**无星号正则表达式(Star-Free Regular Expression)**来构建**模板匹配机制**

Q 为**分解模板(Decomposition template)**, 比如 "你 0 我", 则 "你讨厌我" 和 "你喜欢我" 都可以作为回答

A 为**重组规则(Reassembly rule)**, 比如 "你 0 我", 模型可以回答 "你为什么讨厌我?", 这里的 "0" 会被替换成用户实际说的话

模型尝试将每个用户 input 与一个分解模板匹配, 这个过程是并行的, 意味着模型会同时比较每个用户输入和所有可能的模板, 以找到最合适的匹配

## step3

模型识别出得分最高的模板, 在**选择转换规则**中, 模型不仅考虑模板的匹配度, 还会考虑这个模板在对话中较早匹配的次数, 这样有利于模型更准确地理解对话的上下文

最后模型要生成一个合适的响应, 这一步这几两个重要的**复制机制**:

1. 基于内容的注意力(感应头 attention head)

    通过识别输入序列中的模式来进行复制词

    一种方法是: 通过计算模板被匹配的次数, 使用模运算来选择种族规则, 即模块化前缀和

    另一种方法是: 通过检查模型之前的输出, 来决定下一次的回应

2. 基于位置的注意力.

    依赖词在输入中的位置

    一种方法是: 记忆队列方法, 使用一个自动机, 通过增加或减少状态来跟踪队列中的记忆(Gridword automation)

    另一种方法是: 通过分析模型之前的输出来确定何时从记忆队列中检索记忆(中间输出)

## conclusion

ELIZA 数据集包括多轮对话，每轮对话最多包含 512 个词

基于这些合成数据，团队使用 GPT-2 从头训练了新的 Transformer 模型

新模型包含 8 层解码器，每层有 12 个注意力头，隐藏维度为 768

通过观察模型在学习过程中的表现，团队进一步分析 Transformer 模型在处理对话任务时的行为和学习机制

研究显示，Transformer 模型能够快速学会识别**正确的重组规则**，但需要更长时间来正确实施转换。特别是在多轮对话和内存队列示例中，准确性略低

另外，团队进一步分析了模型的错误，发现模型在**精确复制**方面存在困难，尤其是当需要复制的标记数量较多时。同时，模型在**处理内存队列**时也遇到了挑战，尤其是当前回合与目标内存之间的距离较远时

最重要的是，研究发现 Transformer 模型倾向于根据**对话内容的相似性(Induction Head)**来选择回答，而非严格按照词出现的位置来复制；而且，通过**调整数据属性**可以影响模型学习的机制

**自动可解释性**是指系统能够自动生成解释其决策过程的能力，这对于提高人工智能系统的透明度和可信度非常重要

这种方法包括生成特定的数据集、设计特定的模型架构和训练策略, 从而实现一种结构化和系统化的方法来分析模型的行为, 这一切实现了: 为大语言模型研究提供一个**受控的理想化环境**

@see: https://arxiv.org/abs/2407.10949

@see: https://github.com/princeton-nlp/ELIZA-Transformer

@see: https://x.com/danfriedman0/status/1813168885631263126
